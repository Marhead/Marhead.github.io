---
title: "📝[PTZTA]-Lecture02 Overview"
excerpt: "Sung Kim's PyTorch Lecture 02 review, 성킴 교수님의 머신러닝 강의 리뷰"

categories:
    - Machine-Learning
    - PyTorchZeroToAll
tags:
    - machinelearning
    - python

date: 2021-02-20 05:15:00 +0900
math: true
---

<iframe width="560" height="315" src="https://www.youtube.com/embed/l-Fe9Ekxxj4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

# Model Design
우선 머신러닝의 모델에는 3가지 종류가 있다.
- Supervised Learning
- Unsupervised Learning
- Reinforcement Learning

교수님의 강의에서 사용될 종류의 머신러닝은 Supervised Learning(지도학습) 타입이다.

강의 영상에서는 시간에 따른 점수를 예측하는 모델을 예제삼아 설계를 진행한다.

우선, 지도학습을 하기 위해 주어진 데이터들의 분류가 필요하다. 크게 **Training dataset** 과 **Test dataset**으로 나뉜다. 예제 속 두 데이터셋은 다음과 같다.

| Hours(x) | Points(y) |
| --- | --- |
| 1 | 2 |
| 2 | 4 |
| 3 | 6 |
| 4 | ? |

마지막 "?"의 값을 예측하는 머신러닝 모델을 설계하는 것이 현재의 목표이다.

다음과 같은 데이터를 가장 잘 정리할 수 있는 모델은 선형(Linear)모델이라고 볼 수 있다. 기초적인 선형 방정식을 토대로 나중에 추가될 가중치(weight)개념과 바이어스(bias) 개념까지 활용하여 표현하면 다음과 같다.

$$
\hat{y} = x * w + b
$$

$$
x\rightarrow Linear \rightarrow \hat{y}
$$

두 식중, 위의 식 $\hat{y} = x * w + b$ 에서 b는 더욱 간단한 식의 표현을 위해 생략하고 그래프를 작성하면 다음과 같다.

![]()

위의 그래프의 선은 입력에 대한 정답을 정확히 예측하는 **True Line**이다. 지금부터 우리가 설계한 모델은 해당 True Line에 가장 근접할 수 있는 $w$값을 random guessing한다. 무작위 예측이기 때문에, True Line에서는 빗껴간 다양한 예측 모델들이 등장한다. 그래프 위에 표현하면 다음과 같다.

![]()

지금 부터 우리가 해야 할 일은, 예측된 다양한 그래프들이 최대한 True Line에 가깝게끔 하게 하는 것이다. 그러기 위해서는 그래프 별로 True Line과의 거리를 측정하여 줄이는 것이다. True Line을 $y$, 우리가 만든 그래프를 $\hat{y}$로 보았을 때, 두 그래프의 거리는 $y - \hat{y}$ 이다. 우리에게는 부호의 의미가 필요없고 양이 필요하기에 제곱을 씌어준다. 이렇게 나온 값을 **error(오류)** 라고 부른다. 이러한 오류를 줄이는 것이 최선의 값을 산출해 낼 해법이다.식으로 정리하면 다음과 같다.
$$
loss = (\hat{y} - y)^2 = (x * w - y) ^ 2
$$